{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Genetic Algorithm Research Notes\n",
    "This notebook documents key concepts, intuitions, and paper references for the Evolution Lab genetics system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output Bias Bootstrap Problem\n",
    "**Problem**: With output bias at -1.5, tanh(-1.5) â‰ˆ -0.9, so muscles start nearly fully contracted.\n",
    "**Solution**: Requires coordinated multi-weight changes to overcome. Consider bias closer to 0 for easier exploration.\n",
    "**Reference**: This is a form of the 'bootstrap problem' in neuroevolution - Risi & Stanley (2010)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diversity Maintenance Mechanisms\n",
    "### Fitness Sharing (Goldberg & Richardson, 1987)\n",
    "- Divide fitness by number of similar individuals in niche\n",
    "- Forces population to spread across fitness landscape\n",
    "### Speciation (Stanley & Miikkulainen, 2002)\n",
    "- Group by genetic similarity\n",
    "- Compete within species, not globally\n",
    "- Protects innovation\n",
    "### Novelty Search (Lehman & Stanley, 2011)\n",
    "- Replace fitness with behavioral novelty\n",
    "- Encourages exploration over exploitation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selection Pressure Trade-offs\n",
    "| Method | Pressure | Diversity | Speed |\n",
    "|--------|----------|-----------|-------|\n",
    "| Truncation 50% | High | Low | Fast |\n",
    "| Tournament K=2 | Low | High | Slow |\n",
    "| Tournament K=5 | Medium | Medium | Medium |\n",
    "**Intuition**: High pressure = fast convergence but premature. Low pressure = more diversity but slow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crossover Operators for Neural Networks\n",
    "### Uniform Crossover: DESTRUCTIVE\n",
    "Randomly picks each weight from either parent. Breaks co-adapted weight patterns.\n",
    "### Interpolation/Blend: SAFER  \n",
    "`child = t * parent1 + (1-t) * parent2`. Preserves more parent structure.\n",
    "### SBX (Simulated Binary Crossover): TUNABLE\n",
    "Uses eta parameter to control spread. Higher eta = children closer to parents.\n",
    "**Reference**: Deb & Agrawal (1995)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Papers\n",
    "1. **NEAT**: Stanley, K.O., & Miikkulainen, R. (2002). Evolving Neural Networks through Augmenting Topologies. https://nn.cs.utexas.edu/downloads/papers/stanley.ec02.pdf\n",
    "2. **Fitness Sharing**: Goldberg, D.E., & Richardson, J. (1987). Genetic Algorithms with Sharing for Multimodal Function Optimization.\n",
    "3. **Novelty Search**: Lehman, J., & Stanley, K.O. (2011). Abandoning Objectives: Evolution Through the Search for Novelty Alone.\n",
    "4. **SBX Crossover**: Deb, K., & Agrawal, R.B. (1995). Simulated Binary Crossover for Continuous Search Space.\n",
    "5. **Tournament Selection**: Miller, B.L., & Goldberg, D.E. (1995). Genetic Algorithms, Tournament Selection, and the Effects of Noise."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
