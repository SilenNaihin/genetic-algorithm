{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminary NAS Analysis: 12 Pure Trials\n",
    "\n",
    "## Context\n",
    "\n",
    "**Goal**: Run 100 trials with 150 generations, 500 population, 3 seeds\n",
    "\n",
    "**What happened**: Parallel execution (`n_jobs=5`) failed at production scale - ran sequentially instead\n",
    "\n",
    "**Result**: Only 12 trials completed in 8 hours (should have been ~210 trials)\n",
    "\n",
    "**This notebook**: Analyzes what we learned from those 12 trials\n",
    "\n",
    "---\n",
    "\n",
    "## Key Findings Preview\n",
    "\n",
    "Despite the failed run, these 12 trials provide:\n",
    "- Fitness range validation (best trial: 522.8)\n",
    "- Parameter sensitivity insights\n",
    "- Proof that the pipeline works end-to-end\n",
    "- Baseline for future searches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Trial Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all trial files\n",
    "results_dir = Path('results/search_pure-production-150gen_20260130_091027')\n",
    "trial_files = sorted(results_dir.glob('trial_*.json'))\n",
    "\n",
    "print(f\"Found {len(trial_files)} trial files\")\n",
    "\n",
    "trials = []\n",
    "for trial_file in trial_files:\n",
    "    with open(trial_file) as f:\n",
    "        trials.append(json.load(f))\n",
    "\n",
    "print(f\"Loaded {len(trials)} trials\")\n",
    "print(f\"\\nTrial numbers: {sorted([t['trial_number'] for t in trials])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create Analysis DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract data into structured format\n",
    "data = []\n",
    "for trial in trials:\n",
    "    row = {\n",
    "        'trial_number': trial['trial_number'],\n",
    "        'mean_best_fitness': trial['mean_best_fitness'],\n",
    "        'mean_avg_fitness': trial['mean_avg_fitness'],\n",
    "        'best_fitness_std': np.std(trial['best_fitness_per_seed']),\n",
    "        'best_fitness_max': max(trial['best_fitness_per_seed']),\n",
    "        'best_fitness_min': min(trial['best_fitness_per_seed']),\n",
    "    }\n",
    "    # Add all parameters\n",
    "    row.update(trial['params'])\n",
    "    data.append(row)\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df = df.sort_values('mean_best_fitness', ascending=False)\n",
    "\n",
    "print(f\"DataFrame shape: {df.shape}\")\n",
    "print(f\"\\nParameters explored: {len(df.columns) - 6}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"FITNESS SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nBest trial fitness: {df['mean_best_fitness'].max():.1f}\")\n",
    "print(f\"Worst trial fitness: {df['mean_best_fitness'].min():.1f}\")\n",
    "print(f\"Mean trial fitness: {df['mean_best_fitness'].mean():.1f}\")\n",
    "print(f\"Median trial fitness: {df['mean_best_fitness'].median():.1f}\")\n",
    "print(f\"Std dev: {df['mean_best_fitness'].std():.1f}\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"CROSS-SEED VARIANCE\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nMean std across seeds: {df['best_fitness_std'].mean():.1f}\")\n",
    "print(f\"Max std across seeds: {df['best_fitness_std'].max():.1f}\")\n",
    "print(f\"\\nTrials with high variance (std > 100):\")\n",
    "high_var = df[df['best_fitness_std'] > 100][['trial_number', 'mean_best_fitness', 'best_fitness_std']]\n",
    "print(high_var.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Top 5 Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"TOP 5 TRIALS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "top5 = df.head(5)\n",
    "\n",
    "for idx, row in top5.iterrows():\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Trial {int(row['trial_number'])} - Fitness: {row['mean_best_fitness']:.1f}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"  Std across seeds: {row['best_fitness_std']:.1f}\")\n",
    "    print(f\"  Range: [{row['best_fitness_min']:.1f}, {row['best_fitness_max']:.1f}]\")\n",
    "    print(f\"\\n  Key parameters:\")\n",
    "    print(f\"    Neural hidden size: {int(row['neural_hidden_size'])}\")\n",
    "    print(f\"    Selection: {row['selection_method']}\")\n",
    "    print(f\"    Crossover: {row['use_crossover']}\")\n",
    "    print(f\"    Proprioception: {row['use_proprioception']}\")\n",
    "    print(f\"    Mutation rate: {row['mutation_rate']:.3f}\")\n",
    "    print(f\"    Weight mutation rate: {row['weight_mutation_rate']:.3f}\")\n",
    "    print(f\"    Cull percentage: {row['cull_percentage']:.3f}\")\n",
    "    print(f\"    Max muscles: {int(row['max_muscles'])}\")\n",
    "    print(f\"    Max nodes: {int(row['max_nodes'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Parameter Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze categorical parameters\n",
    "print(\"=\" * 60)\n",
    "print(\"CATEGORICAL PARAMETER FREQUENCIES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "categorical_params = ['selection_method', 'use_crossover', 'use_proprioception', 'neural_hidden_size']\n",
    "\n",
    "for param in categorical_params:\n",
    "    if param in df.columns:\n",
    "        print(f\"\\n{param}:\")\n",
    "        counts = df[param].value_counts()\n",
    "        for val, count in counts.items():\n",
    "            print(f\"  {val}: {count} trials\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Fitness Distribution Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Histogram\n",
    "axes[0].hist(df['mean_best_fitness'], bins=10, edgecolor='black', alpha=0.7)\n",
    "axes[0].axvline(df['mean_best_fitness'].mean(), color='red', linestyle='--', label='Mean')\n",
    "axes[0].axvline(df['mean_best_fitness'].median(), color='green', linestyle='--', label='Median')\n",
    "axes[0].set_xlabel('Mean Best Fitness')\n",
    "axes[0].set_ylabel('Count')\n",
    "axes[0].set_title('Fitness Distribution Across 12 Trials')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Box plot with variance\n",
    "axes[1].scatter(range(len(df)), df['mean_best_fitness'], s=100, alpha=0.6, label='Mean fitness')\n",
    "axes[1].errorbar(range(len(df)), df['mean_best_fitness'], \n",
    "                yerr=df['best_fitness_std'], fmt='none', ecolor='gray', alpha=0.5, capsize=5)\n",
    "axes[1].set_xlabel('Trial (sorted by fitness)')\n",
    "axes[1].set_ylabel('Mean Best Fitness')\n",
    "axes[1].set_title('Trial Fitness with Cross-Seed Variance')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('results/prelim_fitness_distribution.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"Saved: results/prelim_fitness_distribution.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Parameter Correlation with Fitness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correlations for continuous parameters\n",
    "continuous_params = [\n",
    "    'neural_hidden_size', 'weight_mutation_rate', 'weight_mutation_magnitude',\n",
    "    'mutation_rate', 'mutation_magnitude', 'cull_percentage',\n",
    "    'neural_dead_zone', 'neural_output_bias', 'max_muscles', 'max_nodes', 'min_nodes'\n",
    "]\n",
    "\n",
    "available_params = [p for p in continuous_params if p in df.columns]\n",
    "\n",
    "correlations = []\n",
    "for param in available_params:\n",
    "    corr = df[param].corr(df['mean_best_fitness'])\n",
    "    correlations.append({'parameter': param, 'correlation': corr})\n",
    "\n",
    "corr_df = pd.DataFrame(correlations).sort_values('correlation', key=abs, ascending=False)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"PARAMETER CORRELATIONS WITH FITNESS\")\n",
    "print(\"(Limited data - only 12 trials, interpret with caution)\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\n\" + corr_df.to_string(index=False))\n",
    "\n",
    "# Visualize\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "colors = ['red' if abs(c) > 0.3 else 'gray' for c in corr_df['correlation']]\n",
    "ax.barh(corr_df['parameter'], corr_df['correlation'], color=colors, alpha=0.7)\n",
    "ax.axvline(0, color='black', linewidth=0.8)\n",
    "ax.set_xlabel('Correlation with Fitness')\n",
    "ax.set_title('Parameter-Fitness Correlations (12 trials - preliminary)')\n",
    "ax.grid(True, alpha=0.3, axis='x')\n",
    "plt.tight_layout()\n",
    "plt.savefig('results/prelim_parameter_correlations.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nSaved: results/prelim_parameter_correlations.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Selection Method Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'selection_method' in df.columns:\n",
    "    selection_fitness = df.groupby('selection_method')['mean_best_fitness'].agg(['mean', 'std', 'count'])\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(\"SELECTION METHOD COMPARISON\")\n",
    "    print(\"=\" * 60)\n",
    "    print(\"\\n\" + selection_fitness.to_string())\n",
    "    \n",
    "    if len(selection_fitness) > 1:\n",
    "        fig, ax = plt.subplots(figsize=(10, 6))\n",
    "        selection_fitness['mean'].plot(kind='bar', ax=ax, yerr=selection_fitness['std'], \n",
    "                                       capsize=5, alpha=0.7, color='steelblue')\n",
    "        ax.set_ylabel('Mean Best Fitness')\n",
    "        ax.set_title('Selection Method Performance')\n",
    "        ax.grid(True, alpha=0.3, axis='y')\n",
    "        plt.xticks(rotation=0)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('results/prelim_selection_comparison.png', dpi=150, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        print(f\"\\nSaved: results/prelim_selection_comparison.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Crossover Effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'use_crossover' in df.columns:\n",
    "    crossover_fitness = df.groupby('use_crossover')['mean_best_fitness'].agg(['mean', 'std', 'count'])\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(\"CROSSOVER EFFECT\")\n",
    "    print(\"=\" * 60)\n",
    "    print(\"\\n\" + crossover_fitness.to_string())\n",
    "    \n",
    "    if len(crossover_fitness) > 1:\n",
    "        diff = crossover_fitness.loc[True, 'mean'] - crossover_fitness.loc[False, 'mean']\n",
    "        print(f\"\\nCrossover ON vs OFF: {diff:+.1f} fitness difference\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Proprioception Effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'use_proprioception' in df.columns:\n",
    "    proprio_fitness = df.groupby('use_proprioception')['mean_best_fitness'].agg(['mean', 'std', 'count'])\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(\"PROPRIOCEPTION EFFECT\")\n",
    "    print(\"=\" * 60)\n",
    "    print(\"\\n\" + proprio_fitness.to_string())\n",
    "    \n",
    "    if len(proprio_fitness) > 1:\n",
    "        diff = proprio_fitness.loc[True, 'mean'] - proprio_fitness.loc[False, 'mean']\n",
    "        print(f\"\\nProprioception ON vs OFF: {diff:+.1f} fitness difference\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Best Configuration Deep Dive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_trial = df.iloc[0]\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(f\"BEST TRIAL: #{int(best_trial['trial_number'])}\")\n",
    "print(f\"Fitness: {best_trial['mean_best_fitness']:.1f}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\\nFull Configuration:\")\n",
    "print(\"-\" * 60)\n",
    "for col in df.columns:\n",
    "    if col not in ['trial_number', 'mean_best_fitness', 'mean_avg_fitness', \n",
    "                   'best_fitness_std', 'best_fitness_max', 'best_fitness_min']:\n",
    "        val = best_trial[col]\n",
    "        if isinstance(val, float):\n",
    "            print(f\"  {col}: {val:.4f}\")\n",
    "        else:\n",
    "            print(f\"  {col}: {val}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Cross-seed performance:\")\n",
    "print(\"=\"*60)\n",
    "best_trial_data = [t for t in trials if t['trial_number'] == int(best_trial['trial_number'])][0]\n",
    "for i, (seed, fitness) in enumerate(zip(best_trial_data['seeds'], best_trial_data['best_fitness_per_seed'])):\n",
    "    print(f\"  Seed {seed}: {fitness:.1f}\")\n",
    "print(f\"\\nMean: {best_trial['mean_best_fitness']:.1f}\")\n",
    "print(f\"Std: {best_trial['best_fitness_std']:.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Key Insights & Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"KEY INSIGHTS FROM 12 TRIALS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\n1. FITNESS RANGE\")\n",
    "print(f\"   - Best achieved: {df['mean_best_fitness'].max():.1f}\")\n",
    "print(f\"   - Worst: {df['mean_best_fitness'].min():.1f}\")\n",
    "print(f\"   - Range: {df['mean_best_fitness'].max() - df['mean_best_fitness'].min():.1f}\")\n",
    "print(\"   - Strong variance suggests parameter choices matter!\")\n",
    "\n",
    "print(\"\\n2. SEED STABILITY\")\n",
    "print(f\"   - Mean cross-seed std: {df['best_fitness_std'].mean():.1f}\")\n",
    "high_variance_count = len(df[df['best_fitness_std'] > 100])\n",
    "print(f\"   - {high_variance_count}/12 trials had high variance (std > 100)\")\n",
    "if high_variance_count > 6:\n",
    "    print(\"   - WARNING: Many configs are unstable across seeds\")\n",
    "else:\n",
    "    print(\"   - Most configs are reasonably stable\")\n",
    "\n",
    "print(\"\\n3. TOP PARAMETER CORRELATIONS\")\n",
    "top_corrs = corr_df.head(3)\n",
    "for _, row in top_corrs.iterrows():\n",
    "    direction = \"positively\" if row['correlation'] > 0 else \"negatively\"\n",
    "    print(f\"   - {row['parameter']}: {direction} correlated ({row['correlation']:.3f})\")\n",
    "\n",
    "print(\"\\n4. CATEGORICAL INSIGHTS\")\n",
    "if 'selection_method' in df.columns and len(df['selection_method'].unique()) > 1:\n",
    "    best_method = df.groupby('selection_method')['mean_best_fitness'].mean().idxmax()\n",
    "    print(f\"   - Best selection method (avg): {best_method}\")\n",
    "if 'use_crossover' in df.columns and len(df['use_crossover'].unique()) > 1:\n",
    "    crossover_stats = df.groupby('use_crossover')['mean_best_fitness'].mean()\n",
    "    better = \"WITH\" if crossover_stats.get(True, 0) > crossover_stats.get(False, 0) else \"WITHOUT\"\n",
    "    print(f\"   - Better performance: {better} crossover\")\n",
    "if 'use_proprioception' in df.columns and len(df['use_proprioception'].unique()) > 1:\n",
    "    proprio_stats = df.groupby('use_proprioception')['mean_best_fitness'].mean()\n",
    "    better = \"WITH\" if proprio_stats.get(True, 0) > proprio_stats.get(False, 0) else \"WITHOUT\"\n",
    "    print(f\"   - Better performance: {better} proprioception\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"RECOMMENDATIONS FOR NEXT SEARCH\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\n1. Run SEQUENTIAL (n_jobs=1) - parallel doesn't scale\")\n",
    "print(\"2. Use 50-100 trials for meaningful statistics\")\n",
    "print(f\"3. Consider narrowing parameter space around top configs\")\n",
    "print(f\"4. Estimated time: 50 trials × 11.4 min = ~9.5 hours\")\n",
    "print(\"\\n\" + \"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Export Best Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export best config as JSON for easy reuse\n",
    "best_config = {}\n",
    "for col in df.columns:\n",
    "    if col not in ['trial_number', 'mean_best_fitness', 'mean_avg_fitness', \n",
    "                   'best_fitness_std', 'best_fitness_max', 'best_fitness_min']:\n",
    "        val = best_trial[col]\n",
    "        # Convert numpy types to Python types\n",
    "        if hasattr(val, 'item'):\n",
    "            val = val.item()\n",
    "        best_config[col] = val\n",
    "\n",
    "output_file = 'results/best_config_from_12_trials.json'\n",
    "with open(output_file, 'w') as f:\n",
    "    json.dump(best_config, f, indent=2)\n",
    "\n",
    "print(f\"Best configuration saved to: {output_file}\")\n",
    "print(f\"\\nFitness: {best_trial['mean_best_fitness']:.1f}\")\n",
    "print(f\"\\nUse this as a starting point for focused search!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Despite the failed parallel run (12/100 trials), we learned:\n",
    "\n",
    "✅ **Pipeline works**: End-to-end execution successful  \n",
    "✅ **Fitness validation**: Best trial reached 522.8  \n",
    "✅ **Parameter sensitivity**: Clear variation between configs  \n",
    "✅ **Best config identified**: Saved for future use  \n",
    "\n",
    "❌ **Parallel execution**: Failed at production scale  \n",
    "❌ **Statistical power**: 12 trials insufficient for robust conclusions  \n",
    "\n",
    "**Next steps**: Run 50-100 trials sequentially overnight for proper analysis."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
